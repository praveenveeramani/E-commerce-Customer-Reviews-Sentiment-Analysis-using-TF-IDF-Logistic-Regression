{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "3631069c",
      "metadata": {
        "id": "3631069c"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import string\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"train_nykaa_review_sentiment.csv\")"
      ],
      "metadata": {
        "id": "3MI35oGi_bRE"
      },
      "id": "3MI35oGi_bRE",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "9e521b1c",
      "metadata": {
        "id": "9e521b1c"
      },
      "outputs": [],
      "source": [
        "reviews = data['content'][:1500]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15339c9e",
        "outputId": "0c13461d-65f6-4cc9-edc6-4793607fc8bb"
      },
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "id": "15339c9e",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "6854d177",
      "metadata": {
        "id": "6854d177"
      },
      "outputs": [],
      "source": [
        "#Function for text preprocessing\n",
        "def preprocess_text(text):\n",
        "\n",
        "    text = re.sub(r'\\d+','', text) # Remove numbers\n",
        "    text = text.translate(str.maketrans('', '', string.punctuation)) # Remove punctuation\n",
        "    text = text.lower() # Convert text to lowercase\n",
        "    text = ' '.join([word for word in text.split() if word not in stopwords.words('english')]) # Remove stopwords\n",
        "    lemmatizer = WordNetLemmatizer()\n",
        "    text = ' '.join([lemmatizer.lemmatize(word) for word in text.split()]) # Lemmatization\n",
        "    return text\n",
        "\n",
        "#Apply preprocessing to each review\n",
        "preprocessed_reviews = [preprocess_text(review) for review in reviews]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "ad9c6d65",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad9c6d65",
        "outputId": "6ad6ccad-28ee-47ba-be04-9504b011a6cf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      0     1     2     3     4     5     6     7     8     9     ...  1638  \\\n",
            "0      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "1      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "2      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "3      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "4      0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "...    ...   ...   ...   ...   ...   ...   ...   ...   ...   ...  ...   ...   \n",
            "1495   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "1496   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "1497   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "1498   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "1499   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  ...   0.0   \n",
            "\n",
            "          1639  1640  1641  1642  1643  1644  1645  1646  1647  \n",
            "0     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1     0.275343   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "2     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "3     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "4     0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "...        ...   ...   ...   ...   ...   ...   ...   ...   ...  \n",
            "1495  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1496  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1497  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1498  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "1499  0.000000   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0  \n",
            "\n",
            "[1500 rows x 1648 columns]\n"
          ]
        }
      ],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "#Initialize TF-IDF vectorizer\n",
        "tfidf_vectorizer = TfidfVectorizer()\n",
        "\n",
        "#Fit-transform the preprocessed reviews\n",
        "tfidf_matrix = tfidf_vectorizer.fit_transform(preprocessed_reviews)\n",
        "\n",
        "# Convert TF-IDF matrix to DataFrame for visualization\n",
        "tfidf_df = pd.DataFrame(tfidf_matrix.toarray())\n",
        "\n",
        "\n",
        "print(tfidf_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "16b57db8",
      "metadata": {
        "id": "16b57db8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Encode sentiment labels\n",
        "sentiment_mapping = {'POSITIVE': 1, 'NEGATIVE': 0, 'NEUTRAL': 2}\n",
        "data['sentiment_encoded'] = data['sentiment_labels'].map(sentiment_mapping)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(tfidf_df, data['sentiment_encoded'][:1500], test_size=0.15, random_state=42)\n",
        "\n",
        "# Initialize and train logistic regression model\n",
        "logistic_regression = LogisticRegression()\n",
        "logistic_regression.fit(X_train, y_train)\n",
        "\n",
        "# Predict sentiment labels for test data\n",
        "y_pred = logistic_regression.predict(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "67785932",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67785932",
        "outputId": "d986ed2d-63ee-4cb7-8900-b9efbbc72303"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1275\n",
            "225\n",
            "1116    1\n",
            "1368    2\n",
            "422     2\n",
            "413     1\n",
            "451     0\n",
            "       ..\n",
            "1231    1\n",
            "917     1\n",
            "743     1\n",
            "570     1\n",
            "218     2\n",
            "Name: sentiment_encoded, Length: 225, dtype: int64\n",
            "[1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 0\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 0 1 1 1 1 1 1 1 1 2 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1]\n"
          ]
        }
      ],
      "source": [
        "#Ensure that the data splitting process is correct\n",
        "print(len(X_train))\n",
        "print(len(X_test))\n",
        "\n",
        "print(y_test)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "5f5956d8",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5f5956d8",
        "outputId": "bf2f3f2d-1334-4d76-b2f4-4a97ebfc1852"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.7511111111111111\n"
          ]
        }
      ],
      "source": [
        "#Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}